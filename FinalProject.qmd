---
title: "MAT434 Final Project - TMDB Data Analysis"
execute: 
  echo: false
author: "Paul Lamy, Software Engineer and Data Scientist"
format: html
---

```{r echo = FALSE}
# library(tensorflow)
# library(keras)
library(reticulate)

library(dplyr)

library(kableExtra)
library(ggplot2)

use_virtualenv("mat434")
```

## STATEMENT OF PURPOSE
This report takes data from TMDB, a massive online database of films, and examines various characteristics of movies and how these relate to the rating, or vote average, of that movie. Then, two kinds of regression models are constructed, and these can be used to predict the rating of a movie based on those predictor characteristics.


## INTRODUCTION
There are many factors that go into making a movie, some intentional such as budget and the runtime of the film, and others such as the spoken language of the film and the revenue the film earns. TheMovieDataBase, hereforth TMDB, is an online database of almost every single movie ever created. For reference, the dataset for this project is  about 45000 rows long!  

```{python echo=FALSE}
import json
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import ast 
import tkinter
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
# filling in missing data (impute = taking the best guess) 
from sklearn.impute import SimpleImputer
# z scores, 
from sklearn.preprocessing import StandardScaler, OneHotEncoder
# Knn = look at points nearby a certain point, and see if the point has that characteristic
from sklearn.neighbors import KNeighborsClassifier
# decision tree -> if this, do this; else if that, do that
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error
from sklearn.metrics import make_scorer
# RandomForest
from sklearn.ensemble import RandomForestRegressor
# gradient boosting model
from sklearn.ensemble import GradientBoostingClassifier
# Pipeline is a transformation the variables go thru
from sklearn.pipeline import Pipeline
# columns are transformed
from sklearn.compose import ColumnTransformer

# accuracy_score = proportion of predictions that are correct, 
# roc_auc_score = comparisons between true positive rate and false positive rate
from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score

from scipy import stats
```

The original data has columns that are not helpful for the analysis. This data:'

```{python}
data = pd.read_csv('movies_metadata.csv')
data.info()

train, test = train_test_split(data, train_size = 0.75, random_state = 434)
```

becomes

```{python}
columns_to_drop = ["adult","belongs_to_collection", "homepage", "id", "imdb_id", "original_title", "overview", "popularity", "poster_path", "production_companies", "production_countries", "spoken_languages", "status", "tagline", "video", "vote_count"]
columns_to_keep = ["budget", "genre_names", "original_language", "release_date", "runtime"] 
data.drop(columns=columns_to_drop, inplace=True)
data.info()
```

```{python echo=FALSE}
#data['release_date'] = pd.to_datetime(data['release_date'], errors='coerce').astype('float64')
# data['release_date'] = pd.to_datetime(data['release_date'], errors='coerce')
# 
# # errors='coerce' will replace non-numeric values with NaN
# data['budget'] = pd.to_numeric(data['budget'], errors='coerce')
# 
# data['budget'].fillna(data['budget'].median(), inplace=True)
# data['runtime'].fillna(data['runtime'].median(), inplace=True)
# data['original_language'].fillna(data['original_language'].mode()[0], inplace=True)
#data['release_date'] = pd.to_datetime(data['release_date'], errors='coerce').astype('float64')
data['release_date'] = pd.to_datetime(data['release_date'], errors='coerce')
data['release_date']
# errors='coerce' will replace non-numeric values with NaN
data['budget'] = pd.to_numeric(data['budget'], errors='coerce')
# make 'budget' a float column
print(data['budget'])
data['budget'].fillna(data['budget'].median(), inplace=True)
data['runtime'].fillna(data['runtime'].median(), inplace=True)
data['original_language'].fillna(data['original_language'].mode()[0], inplace=True)
data['original_language'].unique()
```

```{python echo=FALSE}
data["genres"] = data["genres"].str.replace("'", '"')
genres_as_dict = data["genres"].apply(lambda x: json.loads(x) if pd.notna(x) else [])
data['genre_names'] = genres_as_dict.apply(lambda genres: [genre['name'] for genre in genres])

# Explode the 'genre_names' column to create separate rows for each genre
exploded_data = data.explode('genre_names')

# Group by 'genre_names' and calculate the median 'vote_average'
median_by_genre = exploded_data.groupby('genre_names')['vote_average'].median().reset_index()

# Display the result
median_by_genre = median_by_genre.dropna(subset=['vote_average'])
```
The following chart displays the number of films for each main language, and displays only the top 20 languages that have the most films.

```{r echo=FALSE}
py$data %>%
  count(original_language) %>%
  top_n(20) %>%
  ggplot() +
  geom_col(aes(x = original_language, y=n, fill = original_language)) +
  labs(
    x = "Original Language",
    y = "Count",
    title = "Number of Films For Main Language"
  ) +
  scale_y_log10() +
  theme_minimal() +
  theme(legend.position="none") +  # Optional: Hide legend if not needed
  coord_flip()  # Optional: Flip the coordinates for horizontal bars
```

```{python echo=FALSE}
original_languages_arr = train["original_language"].unique() 
median_ratings_orig_lang = []

for language in original_languages_arr:
  data_subset = train[train['original_language'] == language]['vote_average']
  # median_vote_avg = np.median()
  if not data_subset.empty and not data_subset.isnull().all():
    median_vote_avg = np.median(data_subset)
    median_ratings_orig_lang.append({'original_language': language, 'median_vote':median_vote_avg})
  
median_ratings_orig_lang_df = pd.DataFrame(median_ratings_orig_lang)
```
This chart compares a movie's budget with its average vote:

```{r echo=FALSE}
py$train %>%
  ggplot() +
  geom_point(aes(x = as.numeric(budget), y=vote_average)) +
  labs(
    x = "Budget",
    y = "Vote Average",
    title = "Film Budget vs. Rating"
  ) +
  scale_x_log10(
    "budget",
    labels = scales::dollar_format()
  )
```
This chart compares a movie's runtime with its average vote:

```{r echo=FALSE}
py$train %>%
  ggplot() +
  geom_point(aes(x = as.numeric(runtime), y=vote_average)) +
  labs(
    x = "Runtime",
    y = "Vote Average",
    title = "Runtime of a Film vs. Rating"
  )
```

This chart shows the relationship between the date a film was released and the average vote:
```{r echo=FALSE}
py$data %>%
  ggplot() +
  geom_point(aes(x = release_date, y=vote_average)) +
  labs(
    x = "Release Date",
    y = "Vote Average",
    title = "Film Release Date vs. Rating"
  )
```

This chart displays the median vote for each genre:
```{r echo=FALSE}
py$median_by_genre %>%
  ggplot() +
  geom_col(aes(x = genre_names, y = vote_average, fill = genre_names)) +
  labs(
    x = "Genre",
    y = "Median Vote",
    title = "Median Rating of Films By Genre"
  ) +
  theme(legend.position="none") + # remove legend since fill is used 
  coord_flip()  # Flip the coordinates for horizontal bars
```

```{python echo=FALSE}
median_ratings_orig_lang_df.info()
median_ratings_orig_lang_df["original_language"].unique()
```

This chart displays the median vote for each original language:
```{r echo=FALSE}
py$median_ratings_orig_lang_df %>%
  count(original_language, median_vote) %>%
  slice_max(order_by = median_vote, n = 20) %>%
  ggplot() +
  geom_col(aes(x = reorder(original_language, median_vote), y = median_vote, fill = original_language)) +
  labs(
    x = "Original Language",
    y = "Median Vote",
    title = "Median Rating of Films For Main Language"
  ) +
  theme(legend.position="none") +
  coord_flip()
```

## Model Construction
In order to see how accurate the prediction of a film's rating is, the models first need to be constructed. Firstly, the `release_date` column will be changed to a format that is better for the modeling pipeline, which is a Unix timestamp. Then, the train data is split into the x and y, where x is all columns except for the `vote_average` and y is the `vote_average` column the model is trying to predict. There is a separation between numerical columns and categorical columns, which is helpful for the pipeline.  

We will utilize 2 different kinds of mathematical models.

The first is Decision tree. The decision tree model looks at points and asks yes or no questions about the points. The 'depth' of the tree is how many questions are asked.

The second is Random Tree Forest Classifier. It uses multiple Decision tree models that are trained on specific data. (multiple trees = a forest).

The modeling workflow for Random Tree Forest is the same as DecisionTree, with the intermediate steps slightly different than the models that were individual models and not ensembles. Here is a brief summary:

1. Make the numerical pipeline. This says how the numbers will be handled by the model. 
2. Make the categorical pipeline. This has already been done above for DT, and the same categorical pipeline is used since categorical values will be handled the same way.
3. Combine the 2 pipelines into a preprocessor. These combined will be used to tell the model how to handle the data.
4. Create the pipeline, which creates the model.
5. Fit the model (allow it to take practice tests).
6. Run the model and let the model make predicitions for the price range for each home (the model has practiced, this is the actual test).
7. Output the results.

Next step is to create the pipeline, or the series of steps for how we will define and set the settings for both of the models. In this notebook, each of the steps for both is described. 

When doing predictions with models, 3 things happens:
Data preprocessing, which is when we organize data to be ready for analysis;
model building which is when we make a prediction algorithm that learns patterns from the data;
and then we evaluate how good the model is by using test data. A pipeline puts all of these steps together in on process 

We first define which relevant columns are numerical and which ones are categorical.
Then we create the pipeline for both Decision Tree. The pipeline for numerical values is different for Decision Tree and Random Tree Forest.

Both model workflows will use the same categorical pipeline, as the way categories are handled will be the same: using SimpleImputer with the most frequent value to fill in missing values, and OneHotEncoder to turn categorical values into True or False.
The preprocessor is what is used to package the numerical and categorical columns together.
After that comes the main pipelines. This combines the preprocessor, which is how the data is handled, with the specific model. 
Then the model must be fit to the data, or 'take practice tests' and have the model 'take the REAL test'. 
After that, we conclude with finding the Root Mean Squared Error of our results for both models.
```{python}
#training and test sets
data['release_date'] = pd.to_datetime(data['release_date'], errors='coerce')
data['release_date'] = data['release_date'].astype('int64') // 10**9  # Convert to Unix timestamp
train, test = train_test_split(data, train_size = 0.75, random_state = 434)

#Split features and response
x_train = train.drop("vote_average", axis = 1)
y_train = train["vote_average"]
x_test = test.drop("vote_average", axis = 1)
y_test = test["vote_average"]

#Create an instance of a model constructor
dt_reg = DecisionTreeRegressor(random_state = 434)

x_train = x_train.drop(["genres", "title"], axis=1)
x_train.info()

#Create a Data Transformation and Model Pipeline
# columns that have numerical values we are interested in
num_cols = ["budget", "release_date", "revenue", "runtime"]
# columns that have categorical values we are interested in
# cat_cols = ["original_language", "genre_names"]
cat_cols = ["original_language"]


cat_pipe = Pipeline([
    ("cat_imputer", SimpleImputer(strategy = "most_frequent")),
    ("one_hot", OneHotEncoder(handle_unknown='ignore'))
])
num_pipe = Pipeline([
    ("num_imputer", SimpleImputer(strategy = "median")),
    ("norm", StandardScaler())
])

preprocessor = ColumnTransformer([
  ("num", num_pipe, num_cols),
  ("cat", cat_pipe, cat_cols)
])

pipe = Pipeline([
    ("preprocessing", preprocessor),
    ("model", dt_reg)
])

# Define a custom scoring function for neg_root_mean_squared_error
def neg_root_mean_squared_error(y_true, y_pred):
    mse = mean_squared_error(y_true, y_pred)
    return -np.sqrt(mse)

# Make it a scorer
neg_root_mean_squared_error_scorer = make_scorer(neg_root_mean_squared_error)
neg_root_mean_squared_error_scorer

y_train = y_train.fillna(y_train.median())
y_test = y_test.fillna(y_test.median())

# This line causes issues
cv_results = cross_val_score(pipe, x_train, y_train, cv=5, scoring=neg_root_mean_squared_error_scorer)

#Collect cross-validation results
cv_results
cv_results.mean()

#Fit model to training data
pipe.fit(x_train, y_train)

#Assess model on test data
test_preds = pipe.predict(x_test)
dt_rmse = np.sqrt(mean_squared_error(y_test, test_preds))
print("Root Mean Squared Error:", dt_rmse)
```

The Root Mean Squared Error for DecisionTreeRegressor is `r py$dt_rmse`.

The above format for model construction is followed for RandomTreeForsest as well.

```{python echo=FALSE}
rf_reg = RandomForestRegressor(max_depth=2, random_state=434)

# pipeline for Random Tree Forst
num_pipe_rtf = Pipeline([
  # SimpleImputer = imputes missing values by using the median
  ("num_imputer", SimpleImputer(strategy = "median")),
])

# cat_pipe = pipeline for processing categorical values
cat_pipe = Pipeline([
  # SimpleImputer = imputes categorical values by using the most frequent vals.
  ("cat_imputer", SimpleImputer(strategy = "most_frequent")),
  # oneHotEncoder = converts categorical features into binary (0 = false or 1 = true)
  ("one-hot", OneHotEncoder(handle_unknown = "ignore"))
])

preprocessor_rtf = ColumnTransformer([
  ("num_cols", num_pipe_rtf, num_cols),
  # applies cat_pipe to categorical values
  ("cat_cols", cat_pipe, cat_cols)
])

pipe_rtf = Pipeline([
  ("preprocessor", preprocessor_rtf),
  ("model", rf_reg)
])

cv_results = cross_val_score(pipe_rtf, x_train, y_train, cv=5, scoring=neg_root_mean_squared_error_scorer)

#Collect cross-validation results
cv_results
cv_results.mean()

#Fit model to training data
pipe.fit(x_train, y_train)

#Assess model on test data
test_preds = pipe.predict(x_test)
rtf_rmse = np.sqrt(mean_squared_error(y_test, test_preds))
rtf_rmse
```

The Root Mean Squared Error for RandomForestRegressor is `r py$rtf_rmse`.